{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.signal import find_peaks, peak_prominences\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_video(file_name: str):\n",
    "    with open(file_name) as f:\n",
    "        video_df = pd.read_csv(file_name, sep=',')\n",
    "        return video_df[[' timestamp', ' confidence', ' pose_Rx', ' pose_Ry', ' pose_Rz']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с корпусными данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_name</th>\n",
       "      <th>spreading_POS</th>\n",
       "      <th>spreading_annot</th>\n",
       "      <th>Annotation_begin</th>\n",
       "      <th>Annotation_end</th>\n",
       "      <th>annot_before</th>\n",
       "      <th>annot_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Поиск 1_166</td>\n",
       "      <td>SUBJ_NOTEXIST</td>\n",
       "      <td>опыт_нет</td>\n",
       "      <td>13690.0</td>\n",
       "      <td>14610.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Поиск 1_104</td>\n",
       "      <td>VERB_NEG</td>\n",
       "      <td>слышать_нет</td>\n",
       "      <td>19850.0</td>\n",
       "      <td>20660.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Поиск 2_226</td>\n",
       "      <td>SUBJ_VERB.NEG</td>\n",
       "      <td>я_не.знать</td>\n",
       "      <td>27530.0</td>\n",
       "      <td>28880.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Поиск 6_10</td>\n",
       "      <td>VERB_NEVER</td>\n",
       "      <td>ехать_никогда</td>\n",
       "      <td>32700.0</td>\n",
       "      <td>33540.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Поиск 2_77</td>\n",
       "      <td>SUBJ_VERB.NEG</td>\n",
       "      <td>я_не.помнить</td>\n",
       "      <td>40290.0</td>\n",
       "      <td>40910.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token_name  spreading_POS spreading_annot  Annotation_begin  \\\n",
       "0  Поиск 1_166  SUBJ_NOTEXIST        опыт_нет           13690.0   \n",
       "1  Поиск 1_104       VERB_NEG     слышать_нет           19850.0   \n",
       "2  Поиск 2_226  SUBJ_VERB.NEG      я_не.знать           27530.0   \n",
       "3   Поиск 6_10     VERB_NEVER   ехать_никогда           32700.0   \n",
       "4   Поиск 2_77  SUBJ_VERB.NEG    я_не.помнить           40290.0   \n",
       "\n",
       "   Annotation_end  annot_before  annot_after  \n",
       "0         14610.0             1            0  \n",
       "1         20660.0             1            0  \n",
       "2         28880.0             1            0  \n",
       "3         33540.0             0            0  \n",
       "4         40910.0             1            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  разметка жестов, на которые распространяется немануальное маркирование, лежит в отдельном файле\n",
    "\n",
    "with open('распространение.csv', encoding='utf-8') as f:\n",
    "    spr_df = pd.read_csv(f, sep=',').iloc[: , :7]\n",
    "\n",
    "spr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negation_type(spr):\n",
    "    if spr == 'DISC':\n",
    "        return 'PART'\n",
    "    elif 'DOUBLE' in spr:\n",
    "        return 'DOUBLE'\n",
    "    elif 'VERB.NEG' in spr:\n",
    "        return 'INCORP'\n",
    "    elif 'VERB_NEG' in spr:\n",
    "        return 'VERB.NEG'\n",
    "    elif 'NOTEXIST' in spr:\n",
    "        return 'VERB.NEG'\n",
    "    elif 'NOBODY' in spr:\n",
    "        return 'PRON'\n",
    "    elif 'NOTHING' in spr:\n",
    "        return 'PRON'\n",
    "    elif 'NEVER' in spr:\n",
    "        return 'PRON'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>annot1</th>\n",
       "      <th>annot2</th>\n",
       "      <th>full_annot</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Поиск 1_0.csv</td>\n",
       "      <td>s14</td>\n",
       "      <td>46990</td>\n",
       "      <td>51660</td>\n",
       "      <td>[(46970, 47650, 'вход'), (47650, 48350, 'собак...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Поиск 1_1.csv</td>\n",
       "      <td>s14</td>\n",
       "      <td>66590</td>\n",
       "      <td>66951</td>\n",
       "      <td>[(66581, 66951, 'нет'), (66951, 67201, 'ладно')]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Поиск 1_2.csv</td>\n",
       "      <td>s21</td>\n",
       "      <td>68415</td>\n",
       "      <td>68725</td>\n",
       "      <td>[(67665, 68415, 'поднять.скатерть'), (68415, 6...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Поиск 1_3.csv</td>\n",
       "      <td>s21</td>\n",
       "      <td>71487</td>\n",
       "      <td>72007</td>\n",
       "      <td>[(69997, 71487, 'кресло'), (71487, 72007, 'нет')]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Поиск 1_4.csv</td>\n",
       "      <td>s23</td>\n",
       "      <td>54005</td>\n",
       "      <td>54345</td>\n",
       "      <td>[(53995, 54345, 'нет'), (54345, 54905, 'точно')]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name path  annot1  annot2  \\\n",
       "0  Поиск 1_0.csv  s14   46990   51660   \n",
       "1  Поиск 1_1.csv  s14   66590   66951   \n",
       "2  Поиск 1_2.csv  s21   68415   68725   \n",
       "3  Поиск 1_3.csv  s21   71487   72007   \n",
       "4  Поиск 1_4.csv  s23   54005   54345   \n",
       "\n",
       "                                          full_annot  other  \n",
       "0  [(46970, 47650, 'вход'), (47650, 48350, 'собак...    NaN  \n",
       "1   [(66581, 66951, 'нет'), (66951, 67201, 'ладно')]    NaN  \n",
       "2  [(67665, 68415, 'поднять.скатерть'), (68415, 6...    NaN  \n",
       "3  [(69997, 71487, 'кресло'), (71487, 72007, 'нет')]    NaN  \n",
       "4   [(53995, 54345, 'нет'), (54345, 54905, 'точно')]    NaN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_token(full_name):\n",
    "    return full_name.split('/')[2].replace('.mp4', '.csv')\n",
    "\n",
    "def get_path(full_path):\n",
    "    return full_path.split('\\\\')[6].replace('.eaf', '').split('-')[2]\n",
    "\n",
    "#  файл с метаинформацией об информанте для каждого фрагмента\n",
    "with open('sentences_info.csv', encoding='utf-8') as inf:\n",
    "    df_inf = pd.read_csv(inf, header=None, names=['name', 'path', 'annot1', 'annot2', 'full_annot', 'other'], sep='\\t')\n",
    "    df_inf['name'] = df_inf.name.apply(get_token)\n",
    "    df_inf['path'] = df_inf.path.apply(get_path)\n",
    "\n",
    "df_inf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_name</th>\n",
       "      <th>timestamps_num</th>\n",
       "      <th>peaks_num</th>\n",
       "      <th>abs_amplitude</th>\n",
       "      <th>peaks_amplitude</th>\n",
       "      <th>check_full_sentence</th>\n",
       "      <th>frequencies</th>\n",
       "      <th>avg_time</th>\n",
       "      <th>informant</th>\n",
       "      <th>spreading</th>\n",
       "      <th>spreading_num</th>\n",
       "      <th>neg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Поиск 1_0.csv</td>\n",
       "      <td>0.240</td>\n",
       "      <td>1</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.253</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>s14</td>\n",
       "      <td>DISC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Поиск 1_104.csv</td>\n",
       "      <td>0.320</td>\n",
       "      <td>3</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.068</td>\n",
       "      <td>False</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>s4</td>\n",
       "      <td>VERB_NEG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VERB.NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Поиск 1_111.csv</td>\n",
       "      <td>0.167</td>\n",
       "      <td>3</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.049</td>\n",
       "      <td>False</td>\n",
       "      <td>11.976048</td>\n",
       "      <td>0.0835</td>\n",
       "      <td>s5</td>\n",
       "      <td>DISC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Поиск 1_112.csv</td>\n",
       "      <td>0.234</td>\n",
       "      <td>5</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.175</td>\n",
       "      <td>False</td>\n",
       "      <td>17.094017</td>\n",
       "      <td>0.0585</td>\n",
       "      <td>s25</td>\n",
       "      <td>DISC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Поиск 1_113.csv</td>\n",
       "      <td>0.166</td>\n",
       "      <td>2</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.212</td>\n",
       "      <td>False</td>\n",
       "      <td>6.024096</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>s17</td>\n",
       "      <td>DISC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PART</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token_name  timestamps_num  peaks_num  abs_amplitude  peaks_amplitude  \\\n",
       "0    Поиск 1_0.csv           0.240          1          0.253            0.253   \n",
       "1  Поиск 1_104.csv           0.320          3          0.110            0.068   \n",
       "2  Поиск 1_111.csv           0.167          3          0.066            0.049   \n",
       "3  Поиск 1_112.csv           0.234          5          0.241            0.175   \n",
       "4  Поиск 1_113.csv           0.166          2          0.230            0.212   \n",
       "\n",
       "  check_full_sentence  frequencies  avg_time informant spreading  \\\n",
       "0                True     0.000000    0.0000       s14      DISC   \n",
       "1               False     6.250000    0.1600        s4  VERB_NEG   \n",
       "2               False    11.976048    0.0835        s5      DISC   \n",
       "3               False    17.094017    0.0585       s25      DISC   \n",
       "4               False     6.024096    0.1660       s17      DISC   \n",
       "\n",
       "   spreading_num  neg_type  \n",
       "0            1.0      PART  \n",
       "1            1.0  VERB.NEG  \n",
       "2            1.0      PART  \n",
       "3            1.0      PART  \n",
       "4            1.0      PART  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negation_info_df = pd.DataFrame(columns=['token_name', 'timestamps_num', 'peaks_num', \n",
    "                                         'abs_amplitude', 'peaks_amplitude', 'check_full_sentence', 'frequencies'])\n",
    "\n",
    "#  обрабатываем отдельно каждый фрагмент с немануальным маркированием, лежащий в отдельной папке\n",
    "\n",
    "\n",
    "for file_name in os.listdir(path='./processed_with_marking/'):\n",
    "    if file_name.endswith('.csv'):\n",
    "        df = get_one_video('./processed_with_marking/'+file_name)\n",
    "        df.columns = ['timestamp', 'confidence', 'pose_Rx', 'pose_Ry', 'pose_Rz']\n",
    "        \n",
    "        #  имя фрагмента\n",
    "        df_dict = {'token_name': file_name}  \n",
    "        \n",
    "        #  первый способ поиска амплитуд, не использованный в дальнейшем\n",
    "        df_dict['abs_amplitude'] = max(df['pose_Ry']) - min(df['pose_Ry'])\n",
    "        \n",
    "        #  находим пики\n",
    "        max_peaks, _ = find_peaks(df['pose_Ry'])\n",
    "        min_peaks, _ = find_peaks(df['pose_Ry'] * (-1))\n",
    "        \n",
    "        #  отфильтровываем пики с минимальной высотой\n",
    "        all_peaks = np.sort(np.concatenate((max_peaks, min_peaks)))\n",
    "        new_peaks = []\n",
    "        y = df['pose_Ry']\n",
    "\n",
    "        if len(all_peaks) > 1:\n",
    "            for i, peak in enumerate(all_peaks):\n",
    "                if peak == all_peaks[0]:\n",
    "                    diff = [abs(y[peak] - y[all_peaks[i+1]])]\n",
    "                elif peak == all_peaks[-1]:\n",
    "                    diff = [abs(y[peak] - y[all_peaks[i-1]])]\n",
    "                else:\n",
    "                    diff = [abs(y[peak] - y[all_peaks[i-1]]), abs(y[peak] - y[all_peaks[i+1]])]\n",
    "\n",
    "                if max(diff) > 0.02:\n",
    "                    new_peaks.append(peak)\n",
    "        else:\n",
    "            new_peaks = all_peaks\n",
    "        \n",
    "        #  запоминаем случаи, где пиков 1 или 0 и считаем амплитуду\n",
    "        if len(new_peaks) <= 1:\n",
    "            df_dict['check_full_sentence'] = True\n",
    "            df_dict['peaks_amplitude'] = df_dict['abs_amplitude']\n",
    "        else:\n",
    "            df_dict['check_full_sentence'] = False\n",
    "            df_dict['peaks_amplitude'] = max(df['pose_Ry'][new_peaks]) - min(df['pose_Ry'][new_peaks])\n",
    "            \n",
    "        df_dict['peaks_num'] = len(new_peaks)\n",
    "        \n",
    "        #  считаем частоту \n",
    "        if len(new_peaks) > 1:\n",
    "            T = (df['timestamp'][new_peaks[-1]] - df['timestamp'][new_peaks[0]]) / (len(new_peaks) - 1)\n",
    "            F = 1 / T\n",
    "            df_dict['avg_time'] = T\n",
    "            df_dict['frequencies'] = F\n",
    "            df_dict['timestamps_num'] = df['timestamp'][new_peaks[-1]] - df['timestamp'][new_peaks[0]]\n",
    "        else:\n",
    "            df_dict['check_full_sentence'] = True\n",
    "            df_dict['avg_time'] = 0\n",
    "            df_dict['frequencies'] = 0\n",
    "            df_dict['timestamps_num'] = df['timestamp'].iat[-1] - df['timestamp'].iat[0]\n",
    "        \n",
    "        #  записываем информацию о количестве жестов, на которые растространяется маркирование\n",
    "        df_dict['spreading'] = spr_df.loc[spr_df['token_name'] == file_name.split('.')[0]]['spreading_POS'].iloc[0]\n",
    "        df_dict['spreading_num'] = len(df_dict['spreading'].replace('VERB_NEG', 'VERB.NEG').split('_'))\n",
    "        \n",
    "        #  записываем информанта\n",
    "        df_dict['informant'] = df_inf.loc[df_inf['name'] == file_name]['path'].values[0]\n",
    "\n",
    "        negation_info_df = negation_info_df.append(df_dict, ignore_index=True)\n",
    "        \n",
    "\n",
    "negation_info_df['peaks_num'] = negation_info_df['peaks_num'].astype('int')\n",
    "negation_info_df['frequencies'] = negation_info_df['frequencies'].astype('float64')\n",
    "negation_info_df['neg_type'] = negation_info_df.spreading.apply(negation_type)\n",
    "\n",
    "negation_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.053858433540954"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negation_info_df[negation_info_df != 0].frequencies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "negation_info_df.to_csv('negation_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Статистика по информантам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peaks_num</th>\n",
       "      <th>peaks_amplitude</th>\n",
       "      <th>frequencies</th>\n",
       "      <th>inf_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>informant</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s1</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.486000</td>\n",
       "      <td>4.991681</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s13</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.259545</td>\n",
       "      <td>6.921145</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s14</th>\n",
       "      <td>5.625000</td>\n",
       "      <td>0.142375</td>\n",
       "      <td>9.117480</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s15</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.056500</td>\n",
       "      <td>9.821429</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s16</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.105500</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s17</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.224300</td>\n",
       "      <td>12.130786</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s18</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>6.298880</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s19</th>\n",
       "      <td>3.727273</td>\n",
       "      <td>0.316727</td>\n",
       "      <td>9.777017</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>3.347826</td>\n",
       "      <td>0.193609</td>\n",
       "      <td>9.263650</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s21</th>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.269500</td>\n",
       "      <td>7.087302</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s22</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s25</th>\n",
       "      <td>6.714286</td>\n",
       "      <td>0.342500</td>\n",
       "      <td>11.654394</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s28</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.661000</td>\n",
       "      <td>10.595194</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s30</th>\n",
       "      <td>3.750000</td>\n",
       "      <td>0.242250</td>\n",
       "      <td>8.892466</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s35</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s36</th>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.174429</td>\n",
       "      <td>10.125557</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s37</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.250667</td>\n",
       "      <td>12.797311</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s39</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>6.051587</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s4</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.293500</td>\n",
       "      <td>10.037442</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s40</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.325556</td>\n",
       "      <td>5.267557</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s41</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.187375</td>\n",
       "      <td>8.626894</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s43</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.170500</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s5</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.126250</td>\n",
       "      <td>8.957405</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           peaks_num  peaks_amplitude  frequencies  inf_count\n",
       "informant                                                    \n",
       "s1          4.000000         0.486000     4.991681          1\n",
       "s13         5.000000         0.259545     6.921145         11\n",
       "s14         5.625000         0.142375     9.117480          8\n",
       "s15         3.500000         0.056500     9.821429          2\n",
       "s16         2.500000         0.105500     7.500000          2\n",
       "s17         6.400000         0.224300    12.130786         10\n",
       "s18         4.000000         0.224000     6.298880          3\n",
       "s19         3.727273         0.316727     9.777017         11\n",
       "s2          3.347826         0.193609     9.263650         23\n",
       "s21         4.333333         0.269500     7.087302          6\n",
       "s22         3.000000         0.101000     8.333333          1\n",
       "s25         6.714286         0.342500    11.654394         14\n",
       "s28         5.000000         0.661000    10.595194          3\n",
       "s30         3.750000         0.242250     8.892466          4\n",
       "s35         3.000000         0.180000    10.000000          1\n",
       "s36         2.857143         0.174429    10.125557          7\n",
       "s37         8.000000         0.250667    12.797311          3\n",
       "s39         2.333333         0.191000     6.051587          3\n",
       "s4          5.000000         0.293500    10.037442          2\n",
       "s40         3.000000         0.325556     5.267557          9\n",
       "s41         3.500000         0.187375     8.626894          8\n",
       "s43         2.500000         0.170500     6.250000          2\n",
       "s5          7.000000         0.126250     8.957405          4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informant_df = negation_info_df.groupby('informant')[['peaks_num', 'peaks_amplitude']].mean()\n",
    "informant_df['frequencies'] = negation_info_df[negation_info_df.frequencies != 0].groupby('informant')['frequencies'].mean()\n",
    "informant_df['inf_count'] = negation_info_df.groupby('informant')['peaks_num'].count()\n",
    "informant_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Статистика по типам отрицания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peaks_num</th>\n",
       "      <th>peaks_amplitude</th>\n",
       "      <th>frequencies</th>\n",
       "      <th>type_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PART</th>\n",
       "      <td>3.315789</td>\n",
       "      <td>0.258868</td>\n",
       "      <td>10.397800</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>5.250000</td>\n",
       "      <td>0.228542</td>\n",
       "      <td>8.460794</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB.NEG</th>\n",
       "      <td>4.776316</td>\n",
       "      <td>0.241934</td>\n",
       "      <td>8.701362</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          peaks_num  peaks_amplitude  frequencies  type_count\n",
       "neg_type                                                     \n",
       "PART       3.315789         0.258868    10.397800          38\n",
       "PRON       5.250000         0.228542     8.460794          24\n",
       "VERB.NEG   4.776316         0.241934     8.701362          76"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df = negation_info_df.groupby('neg_type')[['peaks_num', 'peaks_amplitude']].mean()\n",
    "mean_df['frequencies'] = negation_info_df[negation_info_df.frequencies != 0].groupby('neg_type')['frequencies'].mean()\n",
    "mean_df['type_count'] = negation_info_df.groupby('neg_type')['peaks_num'].count()\n",
    "mean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с элицитированными данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_name</th>\n",
       "      <th>spreading_POS</th>\n",
       "      <th>unnamed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be.not nothing - c3.mp4</td>\n",
       "      <td>VERB.NEG</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>break not nothing - c3.mp4</td>\n",
       "      <td>VERB.NEG</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>call nobody - c1 (1).mp4</td>\n",
       "      <td>NOBODY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>call nobody - c3.mp4</td>\n",
       "      <td>NOBODY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>come not nobody - c3.mp4</td>\n",
       "      <td>VERB.NEG_NOBODY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   token_name    spreading_POS  unnamed\n",
       "0     be.not nothing - c3.mp4         VERB.NEG      NaN\n",
       "1  break not nothing - c3.mp4         VERB.NEG      NaN\n",
       "2    call nobody - c1 (1).mp4           NOBODY      NaN\n",
       "3        call nobody - c3.mp4           NOBODY      NaN\n",
       "4    come not nobody - c3.mp4  VERB.NEG_NOBODY      NaN"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./elicitation/elicitation with marking/sentences_info_e.csv', encoding='utf-8') as inf:\n",
    "    spr_df_e = pd.read_csv(inf, header=None, names=['token_name', 'spreading_POS', 'unnamed'], sep='\\t')\n",
    "\n",
    "spr_df_e.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_informant(file_name):\n",
    "    if 'c1' in file_name:\n",
    "        return 'c1'\n",
    "    elif 'c2' in file_name:\n",
    "        return 'c2'\n",
    "    elif 'c3' in file_name:\n",
    "        return 'c3'\n",
    "    elif 'c4' in file_name:\n",
    "        return 'c4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elic_negation_type(spr):\n",
    "    if ('VERB.NEG' in spr or 'VERB_NEG' in spr) and ('NOBODY' in spr or 'NOTHING' in spr):\n",
    "        return 'DOUBLE'\n",
    "    elif spr == 'NEG_NOTHING':\n",
    "        return 'DOUBLE'\n",
    "    elif spr == 'VERB.NEG':\n",
    "        return 'INCORP'\n",
    "    elif spr == 'VERB_NEG':\n",
    "        return 'VERB.NEG'\n",
    "    elif spr == 'NOBODY':\n",
    "        return 'PRON'\n",
    "    elif spr == 'NOTHING':\n",
    "        return 'PRON'\n",
    "    elif spr == 'NEVER':\n",
    "        return 'PRON'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_name</th>\n",
       "      <th>timestamps_num</th>\n",
       "      <th>peaks_num</th>\n",
       "      <th>abs_amplitude</th>\n",
       "      <th>peaks_amplitude</th>\n",
       "      <th>check_full_sentence</th>\n",
       "      <th>frequencies</th>\n",
       "      <th>avg_time</th>\n",
       "      <th>informant</th>\n",
       "      <th>negation_type</th>\n",
       "      <th>spreading</th>\n",
       "      <th>spreading_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be.not nothing - c3.csv</td>\n",
       "      <td>0.368</td>\n",
       "      <td>2</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.154</td>\n",
       "      <td>False</td>\n",
       "      <td>2.717391</td>\n",
       "      <td>0.368000</td>\n",
       "      <td>c3</td>\n",
       "      <td>VERB.NEG</td>\n",
       "      <td>VERB.NEG</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>break not nothing - c3.csv</td>\n",
       "      <td>0.567</td>\n",
       "      <td>1</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.263</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>c3</td>\n",
       "      <td>VERB.NEG</td>\n",
       "      <td>VERB.NEG</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>call nobody - c1 (1).csv</td>\n",
       "      <td>0.568</td>\n",
       "      <td>5</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.134</td>\n",
       "      <td>False</td>\n",
       "      <td>7.042254</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>c1</td>\n",
       "      <td>PRON</td>\n",
       "      <td>NOBODY</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>call nobody - c3.csv</td>\n",
       "      <td>0.167</td>\n",
       "      <td>2</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.040</td>\n",
       "      <td>False</td>\n",
       "      <td>5.988024</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>c3</td>\n",
       "      <td>PRON</td>\n",
       "      <td>NOBODY</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>come not nobody - c3.csv</td>\n",
       "      <td>1.268</td>\n",
       "      <td>7</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.496</td>\n",
       "      <td>False</td>\n",
       "      <td>4.731861</td>\n",
       "      <td>0.211333</td>\n",
       "      <td>c3</td>\n",
       "      <td>DOUBLE</td>\n",
       "      <td>VERB.NEG_NOBODY</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   token_name  timestamps_num  peaks_num  abs_amplitude  \\\n",
       "0     be.not nothing - c3.csv           0.368          2          0.154   \n",
       "1  break not nothing - c3.csv           0.567          1          0.263   \n",
       "2    call nobody - c1 (1).csv           0.568          5          0.147   \n",
       "3        call nobody - c3.csv           0.167          2          0.198   \n",
       "4    come not nobody - c3.csv           1.268          7          0.496   \n",
       "\n",
       "   peaks_amplitude check_full_sentence  frequencies  avg_time informant  \\\n",
       "0            0.154               False     2.717391  0.368000        c3   \n",
       "1            0.263                True     0.000000  0.000000        c3   \n",
       "2            0.134               False     7.042254  0.142000        c1   \n",
       "3            0.040               False     5.988024  0.167000        c3   \n",
       "4            0.496               False     4.731861  0.211333        c3   \n",
       "\n",
       "  negation_type        spreading  spreading_num  \n",
       "0      VERB.NEG         VERB.NEG            1.0  \n",
       "1      VERB.NEG         VERB.NEG            1.0  \n",
       "2          PRON           NOBODY            1.0  \n",
       "3          PRON           NOBODY            1.0  \n",
       "4        DOUBLE  VERB.NEG_NOBODY            2.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el_negation_info_df = pd.DataFrame(columns=['token_name', 'timestamps_num', 'peaks_num', \n",
    "                                         'abs_amplitude', 'peaks_amplitude', 'check_full_sentence', 'frequencies'])\n",
    "\n",
    "for file_name in os.listdir(path='./elicitation/processed_videos_elicitation_with_marking/'):\n",
    "    if file_name.endswith('.csv'):\n",
    "        df = get_one_video('./elicitation/processed_videos_elicitation_with_marking/'+file_name)\n",
    "        df.columns = ['timestamp', 'confidence', 'pose_Rx', 'pose_Ry', 'pose_Rz']\n",
    "        \n",
    "        #  имя фрагмента\n",
    "        df_dict = {'token_name': file_name}\n",
    "        \n",
    "        #  первый способ поиска амплитуд\n",
    "        df_dict['abs_amplitude'] = max(df['pose_Ry']) - min(df['pose_Ry'])\n",
    "        \n",
    "        #  ищем пики\n",
    "        max_peaks, _ = find_peaks(df['pose_Ry'])\n",
    "        min_peaks, _ = find_peaks(df['pose_Ry'] * (-1))\n",
    "        \n",
    "        #  отфильтровываем пики с минимальной высобой\n",
    "        all_peaks = np.sort(np.concatenate((max_peaks, min_peaks)))\n",
    "        new_peaks = []\n",
    "        y = df['pose_Ry']\n",
    "\n",
    "        if len(all_peaks) > 1:\n",
    "            for i, peak in enumerate(all_peaks):\n",
    "                if peak == all_peaks[0]:\n",
    "                    diff = [abs(y[peak] - y[all_peaks[i+1]])]\n",
    "                elif peak == all_peaks[-1]:\n",
    "                    diff = [abs(y[peak] - y[all_peaks[i-1]])]\n",
    "                else:\n",
    "                    diff = [abs(y[peak] - y[all_peaks[i-1]]), abs(y[peak] - y[all_peaks[i+1]])]\n",
    "\n",
    "                if max(diff) > 0.02:\n",
    "                    new_peaks.append(peak)\n",
    "        else:\n",
    "            new_peaks = all_peaks\n",
    "        \n",
    "        #  записываем случаи, когда пиков 0 или 1 и считаем амплитуды\n",
    "        if len(new_peaks) <= 1:\n",
    "            df_dict['check_full_sentence'] = True\n",
    "            df_dict['peaks_amplitude'] = df_dict['abs_amplitude']\n",
    "        else:\n",
    "            df_dict['check_full_sentence'] = False\n",
    "            df_dict['peaks_amplitude'] = max(df['pose_Ry'][new_peaks]) - min(df['pose_Ry'][new_peaks])\n",
    "            \n",
    "        df_dict['peaks_num'] = len(new_peaks)\n",
    "        \n",
    "        #  считаем частоту \n",
    "        if len(new_peaks) > 1:\n",
    "            T = (df['timestamp'][new_peaks[-1]] - df['timestamp'][new_peaks[0]]) / (len(new_peaks) - 1)\n",
    "            F = 1 / T\n",
    "            df_dict['avg_time'] = T\n",
    "            df_dict['frequencies'] = F\n",
    "            df_dict['timestamps_num'] = df['timestamp'][new_peaks[-1]] - df['timestamp'][new_peaks[0]]\n",
    "        else:\n",
    "            df_dict['check_full_sentence'] = True\n",
    "            df_dict['avg_time'] = 0\n",
    "            df_dict['frequencies'] = 0\n",
    "            df_dict['timestamps_num'] = df['timestamp'].iat[-1] - df['timestamp'].iat[0]\n",
    "        \n",
    "        #  получаем информацию о распространении и видах отрицания\n",
    "        df_dict['spreading'] = spr_df_e.loc[spr_df_e['token_name'] == file_name.replace('.csv', '.mp4')]['spreading_POS'].iloc[0]\n",
    "        df_dict['spreading_num'] = len(df_dict['spreading'].replace('VERB_NEG', 'VERB.NEG').split('_'))\n",
    "        df_dict['negation_type'] = elic_negation_type(df_dict['spreading'])\n",
    "        \n",
    "        #  записываем информацию об информантах\n",
    "        df_dict['informant'] = get_informant(file_name)\n",
    "\n",
    "        el_negation_info_df = el_negation_info_df.append(df_dict, ignore_index=True)\n",
    "        \n",
    "        #plt.plot(df['timestamp'], y)\n",
    "        #plt.plot(df['timestamp'][new_peaks], y[new_peaks], \"x\")\n",
    "        #plt.show()\n",
    "        \n",
    "\n",
    "el_negation_info_df['peaks_num'] = el_negation_info_df['peaks_num'].astype('int')\n",
    "el_negation_info_df['frequencies'] = el_negation_info_df['frequencies'].astype('float64')\n",
    "\n",
    "el_negation_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.584930125579849"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el_negation_info_df[el_negation_info_df != 0].frequencies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_negation_info_df.to_csv('el_negation_info.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
